{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import arff\n",
    "from io import StringIO\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import javalang\n",
    "from pandasgui import show\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "def weka_tokenizer(doc):\n",
    "    delimiters_regexp = re.compile(\"[ |\\n|\\f|\\r|\\t|.|,|;|:|'|\\\"|(|)|?|!]\")\n",
    "    return list(filter(None, delimiters_regexp.split(doc)))\n",
    "\n",
    "idFlakiesProjects = ['redpipe', 'vertexium', 'javaCasClient', 'c2mon', 'vertx', 'excelastic', 'rxjava2', 'tyrus', 'esper', 'yawp', 'luwak', 'fluentLoggerJava', 'delightNashornSandbox', 'dbScheduler', 'one', 'sawmill', 'springCloudZuulRatelimit', 'timely', 'sos', 'openpojo', 'ociJavaSdk', 'aletheia', 'pippo', 'recast4j', 'noxy', 'springCloudAws', 'vertxMqtt', 'vertxRabbitmqClient', 'admiral', 'carbonApimgt', 'riptide', 'fastjson', 'dubbo', 'webcollector', 'doanduyhaiAchilles', 'elasticjoblite', 'disconf', 'hutool', 'oryx', 'querydsl', 'helios', 'retrofit', 'javaWebsocket', 'undertow', 'alien4cloud', 'cukes', 'hsac', 'googdDataCl', 'springDataBean', 'jhispster', 'marineApi', 'junitQuickcheck', 'nexus', 'springDataEnvers', 'springWs', 'aismessages', 'unix4j', 'wikidata', 'activiti', 'jackrabbit', 'struts', 'jfreechart', 'httpRequest', 'wildflymaven', 'nifiRegistry', 'arangoddb', 'dnsjava', 'as2lib', 'whois', 'dbean', 'searchHighlighter', 'wildflymavenplugin', 'balana', 'limfs', 'jodatime', 'otto', 'dropwizard']\n",
    "\n",
    "msr4FlakinessProjects = ['Achilles', 'ambari', 'assertj-core', 'checkstyle', 'commons-exec', 'dropwizard', 'hadoop', 'handlebars', 'hbase', 'hector', 'httpcore', 'jackrabbit-oak', 'jimfs', 'logback', 'ninja', 'okhttp', 'oozie', 'orbit', 'oryx', 'spring-boot', 'alluxio', 'togglz', 'undertow', 'wro4j', 'zxing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "\n",
    "# removing smells classes exceptionCatchingThrowing and dependentTest becouse not has value\n",
    "data = data.drop(columns=['commit', 'testClass', 'testMethod', 'testFilePath', 'productionFilePath', 'relativeTestFilePath', 'relativeProductionFilePath', 'tsTestClass', 'tsTestMethod', 'is_sampled', 'dependentTest', 'exceptionCatchingThrowing', 'smellsCount', 'assertionRoulette', 'conditionalTestLogic', 'constructorInitialization', 'defaultTest', 'dependentTest', 'duplicateAssert', 'eagerTest', 'emptyTest', 'exceptionCatchingThrowing', 'generalFixture', 'ignoredTest', 'lazyTest', 'magicNumberTest', 'mysteryGuest', 'printStatement', 'redundantAssertion', 'resourceOptimism', 'sensitiveEquality', 'sleepyTest', 'unknownTest', 'verboseTest', 'tokens_parser', 'strings_parser', 'string_type_parser', 'anotations_parser'], axis=1)\n",
    "\n",
    "data = data.replace(np.nan, 0)\n",
    "data = data.replace(True, 1)\n",
    "data = data.replace(False, 0)\n",
    "\n",
    "data = data.replace('flaky', 1)\n",
    "data = data.replace('nonflaky', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2800 2777\n"
     ]
    }
   ],
   "source": [
    "# filtering by dataset\n",
    "allMsr4flakiness = data.loc[data.dataset == 'msr4flakiness']\n",
    "before = len(allMsr4flakiness)\n",
    "\n",
    "# filtering by projects\n",
    "smells = allMsr4flakiness.loc[allMsr4flakiness.project.isin(msr4FlakinessProjects)]\n",
    "after = len(smells)\n",
    "\n",
    "smells = smells.reset_index()\n",
    "\n",
    "print(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', max_features=1551, tokenizer=weka_tokenizer)\n",
    "\n",
    "bowToken = vectorizer.fit_transform(smells['vocabulary'])\n",
    "\n",
    "train_vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "vocabularyData = pd.DataFrame(bowToken.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "train = smells.join(vocabularyData, lsuffix='_')\n",
    "\n",
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "keywords_vocabulary = {'abstract', 'assert', 'boolean', 'break', 'byte', 'case', 'catch', 'char', 'class', 'continue', 'default', 'do', 'double', 'else', 'enum', 'exports', 'extends', 'final', 'finally', 'float', 'for', 'if', 'implements', 'import', 'instanceof', 'int', 'interface', 'long', 'modules', 'native', 'new', 'package', 'private', 'protected', 'public', 'requires', 'return', 'short', 'static', 'strictfp', 'super', 'switch', 'synchronized', 'this', 'throw', 'throws', 'transient', 'try', 'void', 'volatile', 'while', 'true', 'null', 'false', 'const', 'goto'}\n",
    "\n",
    "keywordVectorizer = CountVectorizer(analyzer='word', max_features=56, vocabulary=keywords_vocabulary)\n",
    "\n",
    "bowKeywords = keywordVectorizer.fit_transform(smells['keywords_parser'])\n",
    "keywordData = pd.DataFrame(bowKeywords.toarray(), columns=keywordVectorizer.get_feature_names())\n",
    "\n",
    "#creating keywordcount column\n",
    "keywordData[\"count\"] = keywordData[keywordData > 0].count(axis=1)\n",
    "keywordData = keywordData.add_suffix('_keyword')\n",
    "\n",
    "train = train.join(keywordData, lsuffix='_keyword')\n",
    "\n",
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['level_0', 'index_', 'project', 'loc', 'vocabulary', 'keywords_parser',\n",
       "       'klass', 'dataset_', '$radius', '$side',\n",
       "       ...\n",
       "       'this_keyword', 'throw_keyword', 'throws_keyword', 'transient_keyword',\n",
       "       'true_keyword', 'try_keyword', 'void_keyword', 'volatile_keyword',\n",
       "       'while_keyword', 'count_keyword'],\n",
       "      dtype='object', length=1616)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['klass']\n",
    "train = train.drop(['keywords_parser', 'project', 'klass', 'dataset', 'dataset_', 'vocabulary', 'level_0', 'index_', 'index'], axis=1)\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(train, train_y, test_size=0.2, random_state=1) #, random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_old = {\n",
    "        'randomForest': RandomForestClassifier(random_state=1), \n",
    "        'decisionTree': DecisionTreeClassifier(min_samples_leaf=1),\n",
    "        'naiveBayes': GaussianNB(),\n",
    "        'smo': CalibratedClassifierCV(LinearSVC(fit_intercept=False, tol=0.001, C=1, dual=False, max_iter=100000), method='sigmoid'),\n",
    "        'knn': KNeighborsClassifier(n_neighbors=1, metric='euclidean'),\n",
    "        'logisticRegression': LogisticRegression(max_iter=1000),\n",
    "        'perceptron': CalibratedClassifierCV(Perceptron()),\n",
    "        'lda': LinearDiscriminantAnalysis(),\n",
    "    }\n",
    "\n",
    "classifierStatistics = pd.DataFrame(columns=['features', 'process', 'step', 'classifier', 'acc', 'precision', 'recall', 'f1', 'mcc', 'auc', 'VP', 'FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_classifier_old = {}\n",
    "\n",
    "for key, classifier in classifiers_old.items():\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predict = classifier.predict(x_test)\n",
    "    y_probs = classifier.predict_proba(x_test)[:,1]\n",
    "\n",
    "    acc = classifier.score(x_test, y_test)\n",
    "    f1 = f1_score(y_test, predict, average='weighted')  \n",
    "    cr = classification_report(y_test, predict, output_dict=True)  \n",
    "    mcc = matthews_corrcoef(y_test, predict)\n",
    "    auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "    classStatistics = {\n",
    "        'features': 'vocabulary',\n",
    "        'process': 'traditional',\n",
    "        'step': 'training',\n",
    "        'classifier': key,\n",
    "        'acc': acc,\n",
    "        'precision': cr['weighted avg']['precision'],\n",
    "        'recall': cr['weighted avg']['recall'],\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "\n",
    "    classifierStatistics = classifierStatistics.append(classStatistics, ignore_index=True)\n",
    "    trained_classifier_old[key] = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     features      process      step          classifier       acc  precision  \\\n",
       "0  vocabulary  traditional  training        randomForest  0.971223   0.971579   \n",
       "1  vocabulary  traditional  training        decisionTree  0.937050   0.937596   \n",
       "2  vocabulary  traditional  training          naiveBayes  0.951439   0.951548   \n",
       "3  vocabulary  traditional  training                 smo  0.967626   0.967975   \n",
       "4  vocabulary  traditional  training                 knn  0.929856   0.930938   \n",
       "5  vocabulary  traditional  training  logisticRegression  0.967626   0.967975   \n",
       "6  vocabulary  traditional  training          perceptron  0.965827   0.965952   \n",
       "7  vocabulary  traditional  training                 lda  0.866906   0.871221   \n",
       "\n",
       "     recall        f1       mcc       auc  VP  FN  \n",
       "0  0.971223  0.971199  0.942660  0.989448 NaN NaN  \n",
       "1  0.937050  0.937078  0.874501  0.937490 NaN NaN  \n",
       "2  0.951439  0.951416  0.902767  0.950959 NaN NaN  \n",
       "3  0.967626  0.967599  0.935440  0.992352 NaN NaN  \n",
       "4  0.929856  0.929889  0.860675  0.930736 NaN NaN  \n",
       "5  0.967626  0.967599  0.935440  0.994192 NaN NaN  \n",
       "6  0.965827  0.965811  0.931625  0.991794 NaN NaN  \n",
       "7  0.866906  0.866858  0.738208  0.876601 NaN NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>process</th>\n      <th>step</th>\n      <th>classifier</th>\n      <th>acc</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>mcc</th>\n      <th>auc</th>\n      <th>VP</th>\n      <th>FN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>randomForest</td>\n      <td>0.971223</td>\n      <td>0.971579</td>\n      <td>0.971223</td>\n      <td>0.971199</td>\n      <td>0.942660</td>\n      <td>0.989448</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>decisionTree</td>\n      <td>0.937050</td>\n      <td>0.937596</td>\n      <td>0.937050</td>\n      <td>0.937078</td>\n      <td>0.874501</td>\n      <td>0.937490</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>naiveBayes</td>\n      <td>0.951439</td>\n      <td>0.951548</td>\n      <td>0.951439</td>\n      <td>0.951416</td>\n      <td>0.902767</td>\n      <td>0.950959</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>smo</td>\n      <td>0.967626</td>\n      <td>0.967975</td>\n      <td>0.967626</td>\n      <td>0.967599</td>\n      <td>0.935440</td>\n      <td>0.992352</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>knn</td>\n      <td>0.929856</td>\n      <td>0.930938</td>\n      <td>0.929856</td>\n      <td>0.929889</td>\n      <td>0.860675</td>\n      <td>0.930736</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>logisticRegression</td>\n      <td>0.967626</td>\n      <td>0.967975</td>\n      <td>0.967626</td>\n      <td>0.967599</td>\n      <td>0.935440</td>\n      <td>0.994192</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>perceptron</td>\n      <td>0.965827</td>\n      <td>0.965952</td>\n      <td>0.965827</td>\n      <td>0.965811</td>\n      <td>0.931625</td>\n      <td>0.991794</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vocabulary</td>\n      <td>traditional</td>\n      <td>training</td>\n      <td>lda</td>\n      <td>0.866906</td>\n      <td>0.871221</td>\n      <td>0.866906</td>\n      <td>0.866858</td>\n      <td>0.738208</td>\n      <td>0.876601</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "classifierStatistics[classifierStatistics.process == 'traditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting information gain ranking\n",
    "\n",
    "informationGain = dict(zip(train.columns, mutual_info_classif(train, train_y, discrete_features=True)))\n",
    "sortedInformationGain = sorted(informationGain, key=informationGain.get, reverse=True)\n",
    "\n",
    "train_xy = train.join(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sortedInformationGainPosition = []\n",
    "\n",
    "for r in sortedInformationGain:    \n",
    "\n",
    "    infGain = {\n",
    "        'position': i, \n",
    "        'token': r, \n",
    "        'information_gain': informationGain[r],\n",
    "        'total_ocurences': len(train_xy[ train_xy[r] > 0 ] ), \n",
    "        'total_flaky_occurences': len(train_xy[ (train_xy[r] > 0)  & (train_xy['klass'] == 1) ]), \n",
    "        'total_nonflaky_occurences': len(train_xy[ (train_xy[r] > 0)  & (train_xy['klass'] == 0) ])\n",
    "    }\n",
    "\n",
    "    sortedInformationGainPosition.append(infGain)\n",
    "    i += 1\n",
    "\n",
    "infGainDataset = pd.DataFrame(sortedInformationGainPosition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    position                     token  information_gain  total_ocurences  \\\n",
       "0          0                       loc          0.254457             2777   \n",
       "1          1               new_keyword          0.153507             1825   \n",
       "2          2                  services          0.136059              469   \n",
       "3          3            throws_keyword          0.134179             2252   \n",
       "4          4             count_keyword          0.131304             2777   \n",
       "5          5                       get          0.121002              854   \n",
       "6          6                       job          0.109289              387   \n",
       "7          7                      call          0.094981              390   \n",
       "8          8                       xml          0.079836              382   \n",
       "9          9                 getstatus          0.074845              336   \n",
       "10        10            coordinatorjob          0.065946              244   \n",
       "11        11                     getid          0.063430              334   \n",
       "12        12         coordinatoraction          0.061907              230   \n",
       "13        13                jpaservice          0.056479              211   \n",
       "14        14        createmoduleconfig          0.055114              211   \n",
       "15        15              assertequals          0.054852             1332   \n",
       "16        16  addrecordtocoordjobtable          0.054495              204   \n",
       "17        17            public_keyword          0.054245             2769   \n",
       "18        18                      conf          0.053589              256   \n",
       "19        19            return_keyword          0.053424              360   \n",
       "\n",
       "    total_flaky_occurences  total_nonflaky_occurences  \n",
       "0                     1377                       1400  \n",
       "1                     1195                        630  \n",
       "2                      469                          0  \n",
       "3                     1324                        928  \n",
       "4                     1377                       1400  \n",
       "5                      727                        127  \n",
       "6                      387                          0  \n",
       "7                      380                         10  \n",
       "8                      362                         20  \n",
       "9                      325                         11  \n",
       "10                     244                          0  \n",
       "11                     313                         21  \n",
       "12                     230                          0  \n",
       "13                     211                          0  \n",
       "14                       0                        211  \n",
       "15                     886                        446  \n",
       "16                     204                          0  \n",
       "17                    1377                       1392  \n",
       "18                     246                         10  \n",
       "19                     320                         40  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>position</th>\n      <th>token</th>\n      <th>information_gain</th>\n      <th>total_ocurences</th>\n      <th>total_flaky_occurences</th>\n      <th>total_nonflaky_occurences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>loc</td>\n      <td>0.254457</td>\n      <td>2777</td>\n      <td>1377</td>\n      <td>1400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>new_keyword</td>\n      <td>0.153507</td>\n      <td>1825</td>\n      <td>1195</td>\n      <td>630</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>services</td>\n      <td>0.136059</td>\n      <td>469</td>\n      <td>469</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>throws_keyword</td>\n      <td>0.134179</td>\n      <td>2252</td>\n      <td>1324</td>\n      <td>928</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>count_keyword</td>\n      <td>0.131304</td>\n      <td>2777</td>\n      <td>1377</td>\n      <td>1400</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>get</td>\n      <td>0.121002</td>\n      <td>854</td>\n      <td>727</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>job</td>\n      <td>0.109289</td>\n      <td>387</td>\n      <td>387</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>call</td>\n      <td>0.094981</td>\n      <td>390</td>\n      <td>380</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>xml</td>\n      <td>0.079836</td>\n      <td>382</td>\n      <td>362</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>getstatus</td>\n      <td>0.074845</td>\n      <td>336</td>\n      <td>325</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>coordinatorjob</td>\n      <td>0.065946</td>\n      <td>244</td>\n      <td>244</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>getid</td>\n      <td>0.063430</td>\n      <td>334</td>\n      <td>313</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>coordinatoraction</td>\n      <td>0.061907</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>jpaservice</td>\n      <td>0.056479</td>\n      <td>211</td>\n      <td>211</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>createmoduleconfig</td>\n      <td>0.055114</td>\n      <td>211</td>\n      <td>0</td>\n      <td>211</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>assertequals</td>\n      <td>0.054852</td>\n      <td>1332</td>\n      <td>886</td>\n      <td>446</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>addrecordtocoordjobtable</td>\n      <td>0.054495</td>\n      <td>204</td>\n      <td>204</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>public_keyword</td>\n      <td>0.054245</td>\n      <td>2769</td>\n      <td>1377</td>\n      <td>1392</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>conf</td>\n      <td>0.053589</td>\n      <td>256</td>\n      <td>246</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>return_keyword</td>\n      <td>0.053424</td>\n      <td>360</td>\n      <td>320</td>\n      <td>40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "infGainDataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inter- intra-project test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['level_0', 'index', 'project', 'loc', 'vocabulary', 'keywords_parser',\n",
       "       'klass', 'dataset'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "test = data.loc[data.dataset == 'idFlakies']\n",
    "test = test.reset_index()\n",
    "\n",
    "len(test.columns)\n",
    "\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['level_0', 'index_', 'project', 'loc', 'vocabulary', 'keywords_parser',\n",
       "       'klass', 'dataset_', '$radius', '$side',\n",
       "       ...\n",
       "       'yarn', 'yes', 'yield', 'z', '{', '{}', '{}ms', '}', '}</instance>',\n",
       "       '}</value>'],\n",
       "      dtype='object', length=1559)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# Here we are using the trained vocabulary\n",
    "idFlakiesVectorizer = CountVectorizer(analyzer='word', max_features=1551, tokenizer=weka_tokenizer, vocabulary=train_vocabulary) \n",
    "\n",
    "idFlakiesBowToken = idFlakiesVectorizer.fit_transform(test['vocabulary'])\n",
    "\n",
    "idFlakiesVocabularyData = pd.DataFrame(idFlakiesBowToken.toarray(), columns=idFlakiesVectorizer.get_feature_names())\n",
    "\n",
    "test = test.join(idFlakiesVocabularyData, lsuffix='_')\n",
    "\n",
    "len(test.columns)\n",
    "\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "keywordIdFlakiesVectorizer = CountVectorizer(analyzer='word', max_features=56, vocabulary=keywords_vocabulary)\n",
    "\n",
    "bowIdFlakiesKeywords = keywordIdFlakiesVectorizer.fit_transform(test['keywords_parser'])\n",
    "keywordIdFlakiesData = pd.DataFrame(bowIdFlakiesKeywords.toarray(), columns=keywordIdFlakiesVectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "#creating keywordcount column\n",
    "keywordIdFlakiesData[\"count\"] = keywordIdFlakiesData[keywordIdFlakiesData > 0].count(axis=1)\n",
    "keywordIdFlakiesData = keywordIdFlakiesData.add_suffix('_keyword')\n",
    "\n",
    "test = test.join(keywordIdFlakiesData, lsuffix='_keyword')\n",
    "\n",
    "len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr4flakiness = test.loc[test.project.isin(msr4FlakinessProjects)]\n",
    "idflakies = test[test.project.isin(idFlakiesProjects)]\n",
    "\n",
    "msr4flakiness_y = msr4flakiness['klass']\n",
    "idflakies_y = idflakies['klass']\n",
    "\n",
    "msr4flakiness = msr4flakiness.drop(['keywords_parser', 'project', 'klass', 'dataset', 'vocabulary', 'level_0', 'index_', 'dataset_', 'index'], axis=1)\n",
    "idflakies = idflakies.drop(['keywords_parser', 'project', 'klass', 'dataset', 'vocabulary', 'level_0', 'index_', 'dataset_', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['loc', '$radius', '$side', '${2}', '${coord', '${hadoop', '*', '+', '-',\n",
       "       '--',\n",
       "       ...\n",
       "       'this_keyword', 'throw_keyword', 'throws_keyword', 'transient_keyword',\n",
       "       'true_keyword', 'try_keyword', 'void_keyword', 'volatile_keyword',\n",
       "       'while_keyword', 'count_keyword'],\n",
       "      dtype='object', length=1607)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "idflakies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "msr4flakiness samples 35 35\nidflakies samples 120 120\n"
     ]
    }
   ],
   "source": [
    "print('msr4flakiness samples', len(msr4flakiness), len(msr4flakiness_y))\n",
    "print('idflakies samples', len(idflakies), len(idflakies_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "list(set(X_train.columns) - set(msr4flakiness.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, classifier in trained_classifier_old.items():\n",
    "    predict_msr4flakiness = classifier.predict(msr4flakiness)\n",
    "    msr4flakiness_acc = classifier.score(msr4flakiness, msr4flakiness_y)        \n",
    "    cr_msr4flakiness = classification_report(msr4flakiness_y, predict_msr4flakiness, output_dict=True, zero_division=1)\n",
    "    tn_msr4flakiness_, fp_msr4flakiness_, fn_msr4flakiness_, tp_msr4flakiness_ = confusion_matrix(msr4flakiness_y, predict_msr4flakiness, labels=[0,1]).ravel()\n",
    "\n",
    "    classStatistics = {\n",
    "        'features': 'vocabulay',\n",
    "        'process': 'traditional',\n",
    "        'step': 'testing-intra-projects',\n",
    "        'classifier': key,\n",
    "        'acc': msr4flakiness_acc,\n",
    "        'recall': cr_msr4flakiness['1']['recall'],\n",
    "        'VP': tp_msr4flakiness_,\n",
    "        'FN': fn_msr4flakiness_\n",
    "    }\n",
    "\n",
    "    classifierStatistics = classifierStatistics.append(classStatistics, ignore_index=True)\n",
    "\n",
    "    predict_idflakies = classifier.predict(idflakies)\n",
    "    idflakies_acc = classifier.score(idflakies, idflakies_y)\n",
    "    cr_idflakies = classification_report(idflakies_y, predict_idflakies, output_dict=True, zero_division=1)\n",
    "    tn_idflakies_, fp_idflakies_, fn_idflakies_, tp_idflakies_ = confusion_matrix(idflakies_y, predict_idflakies, labels=[0, 1]).ravel()\n",
    "\n",
    "    classStatistics = {\n",
    "        'features': 'vocabulay',\n",
    "        'process': 'traditional',\n",
    "        'step': 'testing-inter-projects',\n",
    "        'classifier': key,\n",
    "        'acc': idflakies_acc,\n",
    "        'recall': cr_idflakies['1']['recall'],\n",
    "        'VP': tp_idflakies_,\n",
    "        'FN': fn_idflakies_\n",
    "    }\n",
    "\n",
    "    classifierStatistics = classifierStatistics.append(classStatistics, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     features      process                    step          classifier  \\\n",
       "8   vocabulay  traditional  testing-intra-projects        randomForest   \n",
       "10  vocabulay  traditional  testing-intra-projects        decisionTree   \n",
       "12  vocabulay  traditional  testing-intra-projects          naiveBayes   \n",
       "14  vocabulay  traditional  testing-intra-projects                 smo   \n",
       "16  vocabulay  traditional  testing-intra-projects                 knn   \n",
       "18  vocabulay  traditional  testing-intra-projects  logisticRegression   \n",
       "20  vocabulay  traditional  testing-intra-projects          perceptron   \n",
       "22  vocabulay  traditional  testing-intra-projects                 lda   \n",
       "\n",
       "         acc  precision    recall  f1  mcc  auc    VP    FN  \n",
       "8   0.171429        NaN  0.171429 NaN  NaN  NaN   6.0  29.0  \n",
       "10  0.314286        NaN  0.314286 NaN  NaN  NaN  11.0  24.0  \n",
       "12  0.171429        NaN  0.171429 NaN  NaN  NaN   6.0  29.0  \n",
       "14  0.085714        NaN  0.085714 NaN  NaN  NaN   3.0  32.0  \n",
       "16  0.571429        NaN  0.571429 NaN  NaN  NaN  20.0  15.0  \n",
       "18  0.200000        NaN  0.200000 NaN  NaN  NaN   7.0  28.0  \n",
       "20  0.342857        NaN  0.342857 NaN  NaN  NaN  12.0  23.0  \n",
       "22  0.285714        NaN  0.285714 NaN  NaN  NaN  10.0  25.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>process</th>\n      <th>step</th>\n      <th>classifier</th>\n      <th>acc</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>mcc</th>\n      <th>auc</th>\n      <th>VP</th>\n      <th>FN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>randomForest</td>\n      <td>0.171429</td>\n      <td>NaN</td>\n      <td>0.171429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>decisionTree</td>\n      <td>0.314286</td>\n      <td>NaN</td>\n      <td>0.314286</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>naiveBayes</td>\n      <td>0.171429</td>\n      <td>NaN</td>\n      <td>0.171429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>smo</td>\n      <td>0.085714</td>\n      <td>NaN</td>\n      <td>0.085714</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>knn</td>\n      <td>0.571429</td>\n      <td>NaN</td>\n      <td>0.571429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>logisticRegression</td>\n      <td>0.200000</td>\n      <td>NaN</td>\n      <td>0.200000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>perceptron</td>\n      <td>0.342857</td>\n      <td>NaN</td>\n      <td>0.342857</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-intra-projects</td>\n      <td>lda</td>\n      <td>0.285714</td>\n      <td>NaN</td>\n      <td>0.285714</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>25.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "classifierStatistics[(classifierStatistics.process == 'traditional') & (classifierStatistics.step == 'testing-intra-projects')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     features      process                    step          classifier  \\\n",
       "9   vocabulay  traditional  testing-inter-projects        randomForest   \n",
       "11  vocabulay  traditional  testing-inter-projects        decisionTree   \n",
       "13  vocabulay  traditional  testing-inter-projects          naiveBayes   \n",
       "15  vocabulay  traditional  testing-inter-projects                 smo   \n",
       "17  vocabulay  traditional  testing-inter-projects                 knn   \n",
       "19  vocabulay  traditional  testing-inter-projects  logisticRegression   \n",
       "21  vocabulay  traditional  testing-inter-projects          perceptron   \n",
       "23  vocabulay  traditional  testing-inter-projects                 lda   \n",
       "\n",
       "         acc  precision    recall  f1  mcc  auc    VP     FN  \n",
       "9   0.266667        NaN  0.266667 NaN  NaN  NaN  32.0   88.0  \n",
       "11  0.366667        NaN  0.366667 NaN  NaN  NaN  44.0   76.0  \n",
       "13  0.125000        NaN  0.125000 NaN  NaN  NaN  15.0  105.0  \n",
       "15  0.166667        NaN  0.166667 NaN  NaN  NaN  20.0  100.0  \n",
       "17  0.225000        NaN  0.225000 NaN  NaN  NaN  27.0   93.0  \n",
       "19  0.300000        NaN  0.300000 NaN  NaN  NaN  36.0   84.0  \n",
       "21  0.333333        NaN  0.333333 NaN  NaN  NaN  40.0   80.0  \n",
       "23  0.558333        NaN  0.558333 NaN  NaN  NaN  67.0   53.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>process</th>\n      <th>step</th>\n      <th>classifier</th>\n      <th>acc</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>mcc</th>\n      <th>auc</th>\n      <th>VP</th>\n      <th>FN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>randomForest</td>\n      <td>0.266667</td>\n      <td>NaN</td>\n      <td>0.266667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>32.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>decisionTree</td>\n      <td>0.366667</td>\n      <td>NaN</td>\n      <td>0.366667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>44.0</td>\n      <td>76.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>naiveBayes</td>\n      <td>0.125000</td>\n      <td>NaN</td>\n      <td>0.125000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>105.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>smo</td>\n      <td>0.166667</td>\n      <td>NaN</td>\n      <td>0.166667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>knn</td>\n      <td>0.225000</td>\n      <td>NaN</td>\n      <td>0.225000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27.0</td>\n      <td>93.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>logisticRegression</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36.0</td>\n      <td>84.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>perceptron</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>0.333333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40.0</td>\n      <td>80.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>vocabulay</td>\n      <td>traditional</td>\n      <td>testing-inter-projects</td>\n      <td>lda</td>\n      <td>0.558333</td>\n      <td>NaN</td>\n      <td>0.558333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>67.0</td>\n      <td>53.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "classifierStatistics[(classifierStatistics.process == 'traditional') & (classifierStatistics.step == 'testing-inter-projects')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}